---
title: "A Deep Dive Into New York Real Estate"
author: "Unique Team B: Mayur Bansal, Huaqiu Chen, Lea Collin, Gengyu Zhang"
date: "05/09/2019"
output:
  prettydoc::html_pretty:
  theme: cayman
highlight: github
---

Note: All of the code for this project can be found [here](https://github.com/LeaCollin0518/AppliedDataScienceFinalProject)

```{r load_libraries, include = FALSE}
library(data.table)
library(DT)
library(tidyverse)
library(extracat)
library(lubridate)
library(choroplethr)
library(choroplethrZip)
```

```{r load_data, include = FALSE}
setwd("~/Columbia/AppliedDS/FinalProject/AppliedDataScienceFinalProject")
all.data <- fread("Data/NYCRealEstateFullData.csv")
all.data$BOROUGH <- NULL
```

```{r functions, include = FALSE}
avg.sale.price.by <- function(data, by.column.names){
  mean.price <- data[, .(`Avg. Price` = mean(get(sale.price.name), na.rm=TRUE)), by = by.column.names]
  return (mean.price)
}

graph.choropleth <- function(data, year){
  keep_cols = c(zip.name, sale.price.name)
  data(zip.regions)
  zip.prices <- data[get(sale.year.name) == year, ..keep_cols]
  zip.prices <- zip.prices[, mean(get(sale.price.name), na.rm = TRUE), by = zip.name]
  colnames(zip.prices) <- c("region", "value")
  zip.prices$value <- as.numeric(zip.prices$value)
  zip.prices$region <- as.character(zip.prices$region)
  zip.prices <- zip.prices[region %in% zip.regions$region,]
  zip.prices <- zip.prices[value > 0,]
  
  plot.title <- c(year, " Average Sale Price by Zip Code")
  plot.title <- paste(plot.title, collapse="")
  
  choro.graph <- zip_choropleth(zip.prices,
                 zip_zoom = zip.prices$region,
                 title       =  plot.title,
                 legend      = "Average Sale Price")
  return (choro.graph)
}

line.plot <- function(data, facet_variable = ''){
  if (facet_variable != ''){
    mean.price <- avg.sale.price.by(data = data, c(sale.year.name))
    setorderv(x = mean.price, cols = "Sale Year", order = 1)
    price.plot <- ggplot(mean.price, aes(`Sale Year`, as.integer(`Avg. Price`))) + 
                   geom_line(size = 1) + geom_point(aes(`Sale Year`,as.integer(`Avg. Price`))) +
                   xlab("Sale Year") + ylab("Avg. Price") +
                   scale_x_continuous(breaks = scales::pretty_breaks(length(mean.price$`Sale Year`))) +
                   ggtitle("NYC Avg. Real Estate Price by Year") 
    return (price.plot)

  }
  else{
    mean.price <- avg.sale.price.by(data, c(sale.year.name, facet_variable))
    setorderv(x = mean.price, cols = "Sale Year", order = 1)
    
    price.plot <- ggplot(mean.price, aes(`Sale Year`, as.integer(`Avg. Price`), color = facet_variable)) + 
                   geom_line(size = 1) + geom_point(aes(`Sale Year`,as.integer(`Avg. Price`))) +
                   xlab("Sale Year") + ylab("Avg. Price") + labs(color = facet_variable) +
                   scale_x_continuous(breaks = scales::pretty_breaks(length(mean.price$`Sale Year`))) +
                   ggtitle("NYC Avg. Real Estate Price by  and Year") 
    return (price.plot)
  }
  
}
```

```{r constants, include = FALSE}
old.borough.name <- "BOROUGH"
borough.name <- "Fixed Borough"
neighborhood.name <- "NEIGHBORHOOD"
building.class.name <- "BUILDING CLASS CATEGORY"
tax.class.name <- "TAX CLASS AT PRESENT"
block.name <- "BLOCK"
lot.name <- "LOT"
easement.name <- "EASE-MENT"
building.class.present.name <- "BUILDING CLASS AT PRESENT"
address.name <- "ADDRESS"
apartment.number.name <- "APARTMENT NUMBER"
zip.name <- "ZIP CODE"
residential.name <- "RESIDENTIAL UNITS"
commercial.name <- "COMMERCIAL UNITS"
total.units.name <- "TOTAL UNITS"
land.square.feet.name <- "LAND SQUARE FEET"
gross.square.feet.name <- "GROSS SQUARE FEET"
year.built.name <- "YEAR BUILT"
tax.class.sale.name <- "TAX CLASS AT TIME OF SALE"
building.class.sale.name <- "BUILDING CLASS AT TIME OF SALE"
sale.price.name <- "SALE PRICE"
sale.date.name <- "SALE DATE"
sale.year.name <- "Sale Year"
log.price.name <- "Log Price"
building.class.first.letter <- "Building Class First Letter"

# also taking the log for future graphing
all.data[, `Log Price` := log(get(sale.price.name))]
all.data[, `Sale Year` := year(get(sale.date.name))]
all.data[, `Building Class First Letter` := substr(get(building.class.sale.name), 1, 1)]
dat <- all.data[get(sale.price.name) > 50000]
```

# Introduction

For our final project, we looked at New York real estate data ranging from 2003 to 2017. The data files include information such as neighborhood, building type, number of units, among many other features. The overarching question of our project is: what factors are important in determining sale price in New York? Throughout this project, we performed extensive exploratory data analysis and build several machine learning models to address this question. However, our analysis was not only limited to this question, we also try to detect facts and trends in New York real estate market through different visualization methods, such as the effect of the 2008 financial crisis to the real estate market and how the price changed during the past 14 years.

This problem is important because New York is notorious for having some of the most expensive real estate in the nation. We were interested in discovering what factors influence these high price tags. When it comes to real estate, it is always said “location, location, location”, we want to find out whether it is true, how it affects house price if it is true and if there are any other factors that can also affect house price. 

# Sources of Data

The data was obtained from NYC Department of Finance. The link to the data can be found [here](https://www1.nyc.gov/site/finance/taxes/property-annualized-sales-update.page). After finding this dataset, we looked at some of the excel files linked on the page and they seemed straightforward to understand and what we hoped for in trying to answer our main question. As the data came from the official Department of Finance, it can be considered as a (presumably) reliable resource. It contains data across 15 years with a number of variables so we felt it could represent the state of New York real estate quite well. We thought there would be many patterns we could discover since the dataset covers 15 years, a time period where a lot of things can change. Furthermore, the dataset has information at the borough and even neighborhood and zip code level so we felt that this would greatly help us answer our questions related to the importance of location. 

# Examination of the Data

The original dataset was broken up by borough. This means there were 5 files for each year (one file per borough) and 15 years so there were 75 separate excel files in total. Thankfully, the columns of each file lined up in obvious ways and we were able to merge all the files into a single .csv file for ease of analysis. The code used to merge all the data can be found [here](https://github.com/LeaCollin0518/AppliedDataScienceFinalProject/blob/master/DataCleaning.Rmd)

The first change we made to the data was re-encoding the borough variable. In the original set, the boroughs were simply numbers. Because we assumed borough would be such an important variable, we wanted to make sure it was the actual borough name. The code to re-encode the variable can be found [here](https://github.com/LeaCollin0518/AppliedDataScienceFinalProject/blob/master/DataCleaning.Rmd)

We checked the quality of the data by inspecting each variable and how it is related to sale price. We also read a few articles on real estate to gain familiarity with the industry as certain things which original seem a bit illogical might become clearer once we get an idea about the nuances of this particular sector. 

We also wanted to know how much data came from each borough so we have a table below that simply shows the count of the number of rows in the dataset coming from each borough. Somewhat surprisingly, the boroughs we have the most rows from are Queens and Brooklyn when we previously thought it would be Manhattan. This could be because Manhattan has so many large buildings that even though many units are sold, many of them by sold all together in one property. 

```{r count_borough, echo = FALSE}
borough.counts <- all.data[, .N, by = borough.name]
colnames(borough.counts) <- c("Borough", "# Rows")
setorderv(x = borough.counts, cols = "# Rows", order = -1)
datatable(borough.counts)
```

### Challenge #1 - Missing Data

One of the most challenging aspects of the dataset was treating missing and unexpected values. Below, we look at how many missing values there are in each column and the patterns of missing values.  

```{r, echo = FALSE}
colSums(is.na(all.data))
```

```{r inspect_na, fig.height = 15, fig.width = 15, echo = FALSE}
visna(all.data, sort = "b")
```

We see that the most common columns that have missing values are "EASE-MENT" and "APARTMENT NUMBER". Both of these have missing values in more than half of all rows. It is probably safe to get rid of these columns and ignore them both in our exploratory analysis and our machine learning model as they likely do not hold any valuable information with so many missing values. It may have been interesting to look at apartment number, to see how the floor of the apartment (ie floor in the building) affects the apartment's price. Otherwise the only other missing valued columns are "TAX CLASS AT PRESENT", "BUILDING CLASS AT PRESENT", "BUILDING CLASS CATEGORY", and "ADDRESS". Address has only 7 missing values in over 1.4 million rows and there are many other columns that indicate the location of these buildings. We see from the graph that Tax Class at Present is always missing whenever Building Class at Present is missing. According to the data source, Tax Class at Present is "based on the use of the property" and Building Class at Present is "used to describe a property’s constructive use", so these two variables are very related. These two variables have the next highest number of missing values, but still only have about 20,000 missing which is not much when compared to the number of rows. 

```{r fix_na, include = FALSE}
all.data$`EASE-MENT` <- NULL
all.data$`APARTMENT NUMBER` <- NULL
```

### Challenge 2 - Unexpected Values

After inspecting the data more carefully, we found certain values which are not missing, but still hamper with the analysis. For example, 30% of the data had a sale price of 0 which does not make sense this could be cause due to a quit claim deed [reference](https://info.courthousedirect.com/blog/bid/309758/how-does-a-quitclaim-deed-affect-your-mortgage ) or according to the data source, a change in owenrship of the property. This was further complicated by the fact that the same property could be present in the dataset with different sale prices (including 0), which may not give us a fair idea about the pricing trends. For these reasons, we decided to simply use properties with a positive sale price. For some analysis and visualizations, we even subsetted the data further because there were also sale prices listed as '1' or '10', which is illogical for the same reasons as a sale price of 0. 

Additionally, the year built variable has 0 values which do not make logical sense and to overcome that we decided to bin the year built values in brackets to give more depth to our analysis. 

### Challenge 3 - Scaling Sale Price

We checked for skewness of different variables in the dataset and found that sale price, which is the dependent variable in our machine learning models, is skewed. Therefore, we standardized the variable by scaling the prices. Below, we plot the density of all sale prices below `$100,000,000 (which eliminates the really high prices and about 1000 rows) and we can't really see the distribution of the data at all. 

```{r inspect_sale_price, echo = FALSE}
density.data <- all.data[get(sale.price.name) < 100000000]

sale.density <- ggplot(density.data, aes(x=as.numeric(`SALE PRICE`))) + 
  geom_density(color = "blue", fill = "#99CCFF") + xlab("Sale Price")

sale.density
```


# Investigation

To answer our questions about the data and the topic, we first got acquainted with what was going on by creating different visualizations to inspect each variable. Our graphs included anything from density curves to visualized continuous variables to bar plots for categorical variables. We also produced line graphs to easily see trends over time. A lot of these graphs were included in our interactive component so that any reader can inspect the data on their own. The interactive component is actually very important because since there are so many years of data, it is hard to create so many visualizations in a static report. The interactive component easily allows the user to discover trends in different years and different variables. All of these graphs can be found in the following **Results** section. 

# Results

Before we jumping into building our machine learning model, we did some detailed exploratory data analysis. This analysis starts with looking at the overall trend of the average sale price. Below, we see a graph of this trend for each borough and the overall dataset. 

```{r avg_sale_price_borough, echo = FALSE}
mean.year.borough.price <- avg.sale.price.by(dat, c(sale.year.name, borough.name))
mean.year.price <- avg.sale.price.by(dat, c(sale.year.name))
mean.year.price$`Fixed Borough` <- "Overall"

all.year.price <- rbind(mean.year.borough.price, mean.year.price)

setorderv(x = all.year.price, cols = "Sale Year", order = 1)
all.year.price <- all.year.price %>% mutate(`Fixed Borough` = forcats::fct_reorder2(`Fixed Borough`, `Sale Year`, `Avg. Price`))

year.borough.price.plot <- ggplot(all.year.price, aes(`Sale Year`, as.integer(`Avg. Price`), color = `Fixed Borough`)) + 
                   geom_line(size = 1) + geom_point(aes(`Sale Year`,as.integer(`Avg. Price`))) +
                   xlab("Sale Year") + ylab("Avg. Price") + labs(color = "Borough") +
                   scale_x_continuous(breaks = scales::pretty_breaks(length(unique(all.year.price$`Sale Year`)))) +
                   scale_color_manual(values=c("#3399FF", "#000000", "#66CC00", "#FF3300", "#9933FF", "#0066CC")) +
                   ggtitle("NYC Avg. Real Estate Price by Borough and Year") 

year.borough.price.plot
```

Not too surprisingly, Manhattan sales prices are the highest among the five boroughs. In recent years, we have seen Brooklyn becoming a more sought-after neighborhood which has led to increases in higher real estate prices, as corroborated by this graph. We should note that since this dataset does not only include apartment buildings, that that is probably also the reason that we see such high real estate prices in Manhattan. Manhattan has many more large buildings than, say, Staten Island which is much more residential. What is also interesting to note is that the Manhattan line follows basically the same trend as the overall city trend because it has the highest prices and is dominating the trend because of it. We see in all five boroughs and the overall trend that there is a dip in prices from 2007 to 2009, very likely caused by the financial crisis. This drop is most noticeable in Manhattan. 


# Interpretation

The results shows that, overall speaking, the New York real estate market suffers from the subprime mortgage crisis which happened from 2006 to 2010. There was a huge drop both in house price and in sale numbers. As the finance center of the world, the real estate market in New York is also closely related to the financial market. 

Our results also confirmed some of our previous assumptions. Manhattan is the most expensive borough while Brooklyn is the second. House prices in Queens and Staten Isalnd are on a similar levels and these two boroughs are the cheapest in New York. 

# Assumptions

# Limitations and Uncertainties

# Areas of Future Investigation

# References

```{r sale_price}
all.data[get(sale.price.name) == 0, .N]
all.data[get(sale.price.name) < 50000, .N]
```

While looking at the data when we were choosing a dataset, we noticed that some sales prices are listed as 0. The documentation for the data claims:

A \$0 sale indicates that there was a transfer of ownership without a cash consideration. There can be a number of reasons for a $0 sale including transfers of ownership from parents to children. 

It may be interesting to look at what kinds of properties are most common in transfers of ownership with no cash consideration, especially since they make up almost a third of our dataset. Furthermore, there are other "weird" values. Such as values of 1 or 10. We'll take a closer look at the types of buildings that list these as their sale price. For now, we will only look at data that has a price of more than 50,000 and continue with our analysis.


We could have also chosen to split this line graph by the building class type. We saw that the building class can be in a "broader" category based on the first letter in the class code. 

```{r need_to_reorganize}
dat <- all.data[get(sale.price.name) > 50000]
residential.codes <- c("A", "B", "C", "D", "RR", "R1", "R2", "R3", "R4", "R6", "R7", "R8", "R9")
residential.properties <- dat[get(building.class.first.letter) %in% residential.codes,]
```

```{r avg_sale_price_code}
mean.year.code.price <- avg.sale.price.by(residential.properties, c(sale.year.name, building.class.first.letter))
setorderv(x = mean.year.code.price, cols = "Sale Year", order = 1)
mean.year.code.price <- mean.year.code.price %>% mutate(`Building Class First Letter` = forcats::fct_reorder2(`Building Class First Letter`, `Sale Year`, `Avg. Price`)) # for coloring

year.code.price.plot <- ggplot(mean.year.code.price, aes(`Sale Year`, as.integer(`Avg. Price`), color = `Building Class First Letter`)) + 
                   geom_line(size = 1) + geom_point(aes(`Sale Year`,as.integer(`Avg. Price`))) +
                   xlab("Sale Year") + ylab("Avg. Price") + labs(color = "Building Class") +
                   scale_x_continuous(breaks = scales::pretty_breaks(length(unique(mean.year.code.price$`Sale Year`)))) +
                   ggtitle("NYC Avg.Residential Real Estate Price by Class Code and Year") 

year.code.price.plot
```

## Need to reorganize with things mentioned further down

We see that the ranking by price remains pretty consistent throughout the 14 year range. "A" type buildings are consistently the buildings with the lowest average price whereas "C" and "D" class buildings are consistetly much higher priced. All of the "D" buildings are elevator buildings which could explain why they are more expensive. Additionally, the "D" class buildings have "luxury apartments" which could be bumping up the average price.

Now we will look at the distribution of each borough's sale prices over the years. For this static report, we will focus only on 2003 and 2017 and look at the distribution for each borough. In our Shiny application, we will give the user a chance to look at each year, however, this is just too much variable information to show in a static report.

```{r boxplot_borough}
box.borough.2017 <- dat[get(sale.year.name) == 2017]
box.borough.2017$`Sale Year` <- as.factor(box.borough.2017$`Sale Year`)

box.borough.2017.plot <- ggplot(box.borough.2017, aes(x = reorder(`Fixed Borough`, -1*`Log Price`, FUN=median), y = `Log Price`)) +
                    geom_boxplot() +
                    xlab("Borough") + ylab("Log Sale Price") + ggtitle("2017 by Borough") +
                    theme(plot.title = element_text(hjust = 0.5))

box.borough.2017.plot

box.borough.2003 <- dat[get(sale.year.name) == 2003]
box.borough.2003$`Sale Year` <- as.factor(box.borough.2003$`Sale Year`)

box.borough.2003.plot <- ggplot(box.borough.2003, aes(x = reorder(`Fixed Borough`, -1*`Log Price`, FUN=median), y = `Log Price`)) +
                    geom_boxplot() +
                    xlab("Borough") + ylab("Log Sale Price") + ggtitle("2003 by Borough") +
                    theme(plot.title = element_text(hjust = 0.5))

box.borough.2003.plot
```

```{r choropleth_map}
graph.choropleth(dat, 2017)
```

As we can see, the range of values for sale price is enormous. Some areas have buildings with an average price of $2.2 billion! This is because the dataset includes any sale of property. Some properties are one-family homes or walk-up apartments while others are office buildings or retail buildings. The most expensive buildings that are likely office spaces can be found in Downtown or Midtown Manhattan. This makes sense as this is where the corporate side of New York resides.  

We can look at the distribution of the data furthermore by building class code. The class codes can be found here: https://www1.nyc.gov/assets/finance/jump/hlpbldgcode.html. The building class at present and building class at time of sale use these building class codes. First, let's take a look at how many rows there are where these codes are not the same. 

```{r unequal_class_code_num}
all.data[get(building.class.present.name) != get(building.class.sale.name), .N]
```

There are `r all.data[get(building.class.present.name) != get(building.class.sale.name), .N]` rows where the building class at present and the building class at time of sale are not the same. For the purposes of visualization and subsetting, we will use the building class at time of sale since we care about the sale price of the property. Now, similar builidng types start with the same letter. For example, building class codes starting with A are one-family homes whereas building class codes starting with B are two-family homes. This means that we can create a new column that is simply the first letter of the building class at the time of sale and this will help us subset our data for visualizations. Based on the documentation, the residential building codes start with: A, B, C, D, and some R. The R codes that don't seem residential are: RA, RB, RG, RH, RK, RP, RS, RT, R0, and R5. Below, we make another data.table with only the residential building class codes at time of sale. 

```{r building_code}
dat <- all.data[get(sale.price.name) > 50000]
residential.codes <- c("A", "B", "C", "D", "RR", "R1", "R2", "R3", "R4", "R6", "R7", "R8", "R9")
residential.properties <- dat[get(building.class.first.letter) %in% residential.codes,]
```

```{r residential_choropleth}
graph.choropleth(residential.properties, 2017)
```

Now that we are only including residential properties, the sales prices are easier to compare between parts of New York. Not surprisingly, many of the most expensive properites are in New York. We see that Staten Island and the Bronx are probably the most affordable. Brooklyn and Queens are also more affordable except the part that are closest to Manhattan are pricier. Even within Manhattan we see trends that make sense. The Upper East side seems to be slightly more expensive than the Upper West side. Midtown isn't terrible whereas Downtown is already getting more expensive. Once we get all the way up to Washington and Inwood Heights, the prices are similar to those in Brooklyn. In the reporting engine, the user can compare different subsets of the data side by side. The user is allowed to choose the year and the building class category to subset by.

Now we'll look at the distribution of the sales prices faceted on different variables, such as year, building class code, borough, or any combination of these. Again, the Shiny app will have all of these options available for the user. For the purposes of this static report, we looked at the residential distributions by borough in 2009 and 2017.

```{r hist_2017_class}
hist.data <- residential.properties[get(sale.price.name) < 5000000 & get(sale.year.name) == 2017,]
res_hist <- ggplot(hist.data, aes(x=as.numeric(`SALE PRICE`))) +
            geom_histogram(color = "blue", fill = "#99CCFF", bins = 75) +
            facet_grid(`Building Class First Letter` ~ .) + xlab("Sale Price")
res_hist
```

```{r hist_2017_borough}
hist.data <- residential.properties[get(sale.price.name) < 5000000 & get(sale.year.name) == 2017,]
res_hist <- ggplot(hist.data, aes(x=as.numeric(`SALE PRICE`))) +
            geom_histogram(color = "blue", fill = "#99CCFF", bins = 75) +
            facet_grid(`Fixed Borough` ~ .) + xlab("Sale Price")
res_hist
```

A problem we are noticing as we look more and more at the data is that it is never clear if the buyer purchased one unit in the property or if they purchased all the units in the property. For example, one residential property sold for around $4 billion and had around 8000 units which is about $500,000 per unit (which would be reasonable). However, other times a property seems to have sold for $53 million for a single unit. The dataset doesn't provide a lot of information on when a single unit within the property was purchased and when the whole building was purchased. Furthermore, sometimes the unit information is not even present.

Now we take a look at the building class codes and their breakdown across the boroughs. The description of the class codes can be found [here](https://www1.nyc.gov/assets/finance/jump/hlpbldgcode.html). Below, we have a bar graph of the number of buildings of each code class in the dataset in each borough. Because there are so many building codes and many had such a negligible amount sold in the data, we plotted only the rows that had more than 250 sold. Note below that we are showing the raw counts, not the proportions. 

```{r building_codes, fig.height = 10, fig.width = 20}
summary.building.codes <- all.data[, .N, by = c(building.class.first.letter, borough.name)]

summary.building.codes <- summary.building.codes[N > 250, ]

code.plot <- ggplot(summary.building.codes, aes(x = reorder(`Building Class First Letter`, -1*`N`), y = `N`, fill = `Fixed Borough`)) +
             geom_bar(stat = 'identity', position="dodge") + xlab("Building Class Code") + ylab("# Sold") + labs(fill = "Borough") +
             theme_minimal(base_size = 20)

code.plot
```

There are a few interesting things that stand out from this graph. For one, Manhattan is the only borough that has buldings of type **H** and **L**. Buildings with a class code starting with **H** are generally hotels, motels, or hostels and **L** buildings lofts. The hotels being sold only in Manhattan isn't too surprising as we know that there are many hotels here and the other boroughs are generally more residential. This doesn't mean that there are no hotels in the other boroughs however, it simply shows that none were **sold** during this 14-year period of time. Buildings with an **R** class code seem to be some of the most popular, but they are also the most mixed. According to our data source, these properties range from indoor parking and office spaces to condos in buildings with other residential units. Again, Manhattan has the most sales. Building codes of class **A** are all of the one-family properties and we see that Queens and Staten Island have the highest number of those (Manhattan barely has any). Brooklyn and QUeens have almost the same number of **B** properties sold, which are all two-family properties. All of this once again reaffirms our idea that Manhattan is mainly large buildings and the smaller boroughs are more residential. Some of the lowest counts in building class codes are **I** and **W**. **I** codes are for buildings such as nursing homes and hospitals and **W** is for schools and university buildings (these aren't exactly the hottest properties). 